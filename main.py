# main.py - ·ª®ng d·ª•ng Streamlit

import streamlit as st
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
import joblib
from sklearn.model_selection import train_test_split
from sklearn.metrics import mean_squared_error, r2_score
from xgboost import XGBRegressor

st.set_page_config(layout="wide")
st.title("üìà Zara Sales Forecasting App")

# 1. Load d·ªØ li·ªáu
st.subheader("1. T·∫£i v√† ti·ªÅn x·ª≠ l√Ω d·ªØ li·ªáu")
df = pd.read_csv("https://raw.githubusercontent.com/nguyenvudev20/zaraforcasting/refs/heads/main/zara.csv", delimiter=";")

df = df.dropna(subset=['name', 'description'])
df['scraped_at'] = pd.to_datetime(df['scraped_at'], errors='coerce')
df['Promotion'] = df['Promotion'].str.strip().str.lower()
df['Seasonal'] = df['Seasonal'].str.strip().str.lower()
df['Product Category'] = df['Product Category'].str.strip().str.title()
df['section'] = df['section'].str.strip().str.upper()
df['price_category'] = pd.qcut(df['price'], q=3, labels=['low', 'medium', 'high'])
df['scrape_month'] = df['scraped_at'].dt.month
df['scrape_dayofweek'] = df['scraped_at'].dt.dayofweek

st.write("‚úÖ D·ªØ li·ªáu ƒë√£ ƒë∆∞·ª£c ti·ªÅn x·ª≠ l√Ω. D∆∞·ªõi ƒë√¢y l√† v√†i d√≤ng ƒë·∫ßu:")
st.dataframe(df.head())

# 2. Tr·ª±c quan h√≥a d·ªØ li·ªáu
st.subheader("2. Tr·ª±c quan h√≥a d·ªØ li·ªáu")

# Ph√¢n ph·ªëi gi√°
fig1, ax1 = plt.subplots()
sns.histplot(df['price'], bins=20, kde=True, ax=ax1)
ax1.set_title("Ph√¢n ph·ªëi gi√° s·∫£n ph·∫©m")
st.pyplot(fig1)

# S·∫£n ph·∫©m khuy·∫øn m√£i
fig2, ax2 = plt.subplots()
df['Promotion'].value_counts().plot(kind='bar', ax=ax2)
ax2.set_title("S·∫£n ph·∫©m c√≥/kh√¥ng khuy·∫øn m√£i")
st.pyplot(fig2)

# Doanh s·ªë theo m·ª©c gi√°
fig3, ax3 = plt.subplots()
df.groupby('price_category')['Sales Volume'].mean().plot(kind='bar', color='orange', ax=ax3)
ax3.set_title("Doanh s·ªë trung b√¨nh theo m·ª©c gi√°")
st.pyplot(fig3)

# S·∫£n ph·∫©m theo ng√†y thu th·∫≠p
fig4, ax4 = plt.subplots()
df['scraped_at'].dt.date.value_counts().sort_index().plot(marker='o', ax=ax4)
ax4.set_title("S·∫£n ph·∫©m theo ng√†y thu th·∫≠p")
ax4.set_xlabel("Ng√†y")
ax4.set_ylabel("S·ªë l∆∞·ª£ng")
st.pyplot(fig4)

# Heatmap
fig5, ax5 = plt.subplots(figsize=(10, 6))
sns.heatmap(df.select_dtypes(include=[np.number]).corr(), annot=True, cmap="coolwarm", ax=ax5)
ax5.set_title("Ma tr·∫≠n t∆∞∆°ng quan ƒë·∫∑c tr∆∞ng s·ªë")
st.pyplot(fig5)

# 3. Hu·∫•n luy·ªán m√¥ h√¨nh
st.subheader("3. Hu·∫•n luy·ªán m√¥ h√¨nh d·ª± ƒëo√°n doanh s·ªë")

features = ['price', 'Promotion', 'Product Position', 'Seasonal', 'section', 'price_category', 'scrape_month', 'scrape_dayofweek']
X = pd.get_dummies(df[features], drop_first=True)
y = np.log1p(df['Sales Volume'])

X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

model = XGBRegressor(n_estimators=100, max_depth=5, learning_rate=0.1, random_state=42)
model.fit(X_train, y_train)

# D·ª± ƒëo√°n & ƒë√°nh gi√°
y_pred_log = model.predict(X_test)
y_pred = np.expm1(y_pred_log)
y_true = np.expm1(y_test)

mse = mean_squared_error(y_true, y_pred)
r2 = r2_score(y_true, y_pred)

st.write(f"üìâ **Mean Squared Error (MSE):** `{mse:,.2f}`")
st.write(f"üìà **R-squared Score (R¬≤):** `{r2:.4f}`")

# Bi·ªÉu ƒë·ªì th·ª±c t·∫ø vs d·ª± ƒëo√°n
fig6, ax6 = plt.subplots()
ax6.scatter(y_true, y_pred, alpha=0.6)
ax6.plot([y_true.min(), y_true.max()], [y_true.min(), y_true.max()], '--r')
ax6.set_xlabel("Gi√° tr·ªã th·ª±c t·∫ø")
ax6.set_ylabel("Gi√° tr·ªã d·ª± ƒëo√°n")
ax6.set_title("Doanh s·ªë: Th·ª±c t·∫ø vs D·ª± ƒëo√°n")
ax6.grid(True)
st.pyplot(fig6)

